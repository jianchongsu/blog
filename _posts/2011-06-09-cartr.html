--- 
layout: post
name: cartr
title: "\xE5\x88\x86\xE7\xB1\xBB-\xE5\x9B\x9E\xE5\xBD\x92\xE6\xA0\x91\xE6\xA8\xA1\xE5\x9E\x8B\xEF\xBC\x88CART\xEF\xBC\x89\xE5\x9C\xA8R\xE8\xAF\xAD\xE8\xA8\x80\xE4\xB8\xAD\xE7\x9A\x84\xE5\xAE\x9E\xE7\x8E\xB0"
date: 2011-06-09 09:35:00 +08:00
categories: 
- "\xE5\x86\xB3\xE7\xAD\x96\xE6\xA0\x91"
permalink: /2011/06/cartr.html
---
<b>CART模型</b>，即Classification And Regression Trees。它和一般回归分析类似，是用来对变量进行解释和预测的工具，也是数据挖掘中的一种常用算法。如果因变量是连续数据，相对应的分析称为回归树，如果因变量是分类数据，则相应的分析称为分类树。<br /><br />决策树是一种倒立的树结构，它由内部节点、叶子节点和边组成。其中最上面的一个节点叫根节点。 构造一棵决策树需要一个训练集，一些例子组成，每个例子用一些属性（或特征）和一个类别标记来描述。构造决策树的目的是找出属性和类别间的关系，一旦这种关系找出，就能用它来预测将来未知类别的记录的类别。这种具有预测功能的系统叫决策树分类器。其算法的优点在于:1)可以生成可以理解的规则。2)计算量相对来说不是很大。3)可以处理多种数据类型。4)决策树可以清晰的显示哪些变量较重要。<br /><br />下面以一个例子来讲解如何在R语言中建立树模型。为了预测身体的肥胖程度，可以从身体的其它指标得到线索，例如：腰围、臀围、肘宽、膝宽、年龄。<br /><a name='more'></a><br /><br />#首先载入所需软件包<br />library(mboost)<br />library(rpart)<br />library(maptree)<br /><br />#读入样本数据<br />data('bodyfat')<br /><br />#建立公式<br />formular=DEXfat~age+waistcirc+hipcirc+elbowbreadth+kneebreadth<br /><br />#用rpart命令构建树模型，结果存在fit变量中<br />fit=rpart(formular,method='anova',data=bodyfat)<br /><br />#直接调用fit可以看到结果<br />n= 71<br />node), split, n, deviance, yval<br />&nbsp; &nbsp; &nbsp; * denotes terminal node<br /><br />&nbsp;1) root 71 8535.98400 30.78282 <br />&nbsp; &nbsp;2) waistcirc&lt; 88.4 40 1315.35800 22.92375 <br />&nbsp; &nbsp; &nbsp;4) hipcirc&lt; 96.25 17 &nbsp;285.91370 18.20765 *<br />&nbsp; &nbsp; &nbsp;5) hipcirc&gt;=96.25 23 &nbsp;371.86530 26.40957 <br />&nbsp; &nbsp; &nbsp; 10) waistcirc&lt; 80.75 13 &nbsp;117.60710 24.13077 *<br />&nbsp; &nbsp; &nbsp; 11) waistcirc&gt;=80.75 10 &nbsp; 98.99016 29.37200 *<br />&nbsp; &nbsp;3) waistcirc&gt;=88.4 31 1562.16200 40.92355 <br />&nbsp; &nbsp; &nbsp;6) hipcirc&lt; 109.9 13 &nbsp;136.29600 35.27846 *<br />&nbsp; &nbsp; &nbsp;7) hipcirc&gt;=109.9 18 &nbsp;712.39870 45.00056 *<br /><br />#也可以用画图方式将结果表达得更清楚一些<br />draw.tree(fit)<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-gUimPTaTkMo/TfAg9hVMb9I/AAAAAAAAAQM/0mw9iG3pq54/s1600/test.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://2.bp.blogspot.com/-gUimPTaTkMo/TfAg9hVMb9I/AAAAAAAAAQM/0mw9iG3pq54/s1600/test.jpg" /></a></div>#建立树模型要权衡两方面问题，一个是要拟合得使分组后的变异较小，另一个是要防止过度拟合，而使模型的误差过大，前者的参数是CP，后者的参数是Xerror。所以要在Xerror最小的情况下，也使CP尽量小。如果认为树模型过于复杂，我们需要对其进行修剪<br />#首先观察模型的误差等数据<br />printcp(fit)<br /><br />Regression tree:<br />rpart(formula = formula, data = bodyfat)<br /><br />Variables actually used in tree construction:<br />[1] hipcirc &nbsp; waistcirc<br /><br />Root node error: 8536/71 = 120.23<br /><br />n= 71<br /><br />&nbsp; &nbsp; &nbsp; &nbsp; CP nsplit rel error &nbsp;xerror &nbsp; &nbsp; xstd<br />1 0.662895 &nbsp; &nbsp; &nbsp;0 &nbsp; 1.00000 1.01364 0.164726<br />2 0.083583 &nbsp; &nbsp; &nbsp;1 &nbsp; 0.33710 0.41348 0.094585<br />3 0.077036 &nbsp; &nbsp; &nbsp;2 &nbsp; 0.25352 0.42767 0.084572<br />4 0.018190 &nbsp; &nbsp; &nbsp;3 &nbsp; 0.17649 0.31964 0.062635<br />5 0.010000 &nbsp; &nbsp; &nbsp;4 &nbsp; 0.15830 0.28924 0.062949<br /><br />#调用CP（complexity parameter）与xerror的相关图，一种方法是寻找最小xerror点所对应的CP值，并由此CP值决定树的大小，另一种方法是利用1SE方法，寻找xerror+SE的最小点对应的CP值。<br />plotcp(fit)<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-mdzscs5fZL4/TfAhIpUhsOI/AAAAAAAAAQQ/kEryrx-J5WA/s1600/test2.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="399" src="http://3.bp.blogspot.com/-mdzscs5fZL4/TfAhIpUhsOI/AAAAAAAAAQQ/kEryrx-J5WA/s400/test2.jpg" width="400" /></a></div><br />#用prune命令对树模型进行修剪(本例的树模型不复杂，并不需要修剪)<br />pfit=prune(fit,cp= fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])<br /><br />#模型初步解释：腰围和臀围较大的人，肥胖程度较高，而其中腰围是最主要的因素。<br />#利用模型预测某个人的肥胖程度<br /><br />ndata=data.frame(waistcirc=99,hipcirc=110,elbowbreadth=6,kneebreadth=8,age=60)<br />predict(fit,newdata=ndata)<br /><br />*本文主要参考了Yanchang Zhao的文章:“R and Data Mining: Examples and Case Studies”
