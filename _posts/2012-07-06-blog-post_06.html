--- 
layout: post
name: blog-post_06
title: "\xE8\xB0\x88\xE4\xB8\x80\xE8\xB0\x88\xE6\x94\xAF\xE6\x8C\x81\xE5\x90\x91\xE9\x87\x8F\xE6\x9C\xBA\xE5\x88\x86\xE7\xB1\xBB\xE5\x99\xA8"
date: 2012-07-06 12:56:00 +08:00
categories: 
- "\xE6\x94\xAF\xE6\x8C\x81\xE5\x90\x91\xE9\x87\x8F\xE6\x9C\xBA"
- "\xE6\x95\xB0\xE6\x8D\xAE\xE6\x8C\x96\xE6\x8E\x98"
- "\xE4\xBA\xA4\xE5\x8F\x89\xE6\xA3\x80\xE9\xAA\x8C"
permalink: /2012/07/blog-post_06.html
---
<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-ebAXm6lvSxk/T_ZtVddAPeI/AAAAAAAABBI/ueTs0Bln0LI/s1600/1.png" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" height="196" src="http://3.bp.blogspot.com/-ebAXm6lvSxk/T_ZtVddAPeI/AAAAAAAABBI/ueTs0Bln0LI/s200/1.png" width="200" /></a></div><span style="background-color: white;"><b>支持向量机（Support Vector Machine）</b>名字听起来很炫，功能也很炫，但公式理解起来常有眩晕感。所以本文尝试不用一个公式来说明SVM的原理，以保证不吓跑一个读者。理解SVM有四个关键名词：<b>分离超平面、最大边缘超平面、软边缘、核函数</b>。</span><br /><br /><ul><li><span style="background-color: white;"><b>分离超平面<b>（</b>separating hyperplane</b><b>）</b>：处理分类问题的时候需要一个决策边界，好象楚河汉界一样，在界这边我们判别A，在界那边我们判别B。这种决策边界将两类事物相分离，而线性的决策边界就是分离超平面。</span></li><li><span style="background-color: white;"><b>最大边缘超平面（Maximal Margin Hyperplane）</b>：分离超平面可以有很多个，怎么找最好的那个呢，SVM的作法是找一个“最中间”的。换句话说，就是这个平面要尽量和两边保持距离，以留足余量，减小泛化误差，保证稳健性。或者用中国人的话讲叫做“执中”。以江河为国界的时候，就是以航道中心线为界，这个就是最大边缘超平面的体现。在数学上找到这个最大边缘超平面的方法是一个二次规划问题。</span></li><li><span style="background-color: white;"><b>软边缘（Soft Margin)</b>：但世界上没这么美的事，很多情况下都是“你中有我，我中有你”的混杂状态。不大可能用一个平面完美的分离两个类别。在线性不可分情况下就要考虑软边缘了。软边缘可以破例允许个别样本跑到其它类别的地盘上去。但要使用参数来权衡两端，一个是要保持最大边缘的分离，另一个要使这种破例不能太离谱。这种参数就是对错误分类的惩罚程度C。</span></li><li><span style="background-color: white;"><b>核函数(Kernel Function)，</b>为了解决完美分离的问题，SVM还提出一种思路，就是将原始数据映射到高维空间中去，直觉上可以感觉高维空间中的数据变的稀疏，有利于“分清敌我”。那么映射的方法就是使用“核函数”。如果这种“核技术”选择得当，高维空间中的数据就变得容易线性分离了。而且可以证明，总是存在一种核函数能将数据集映射成可分离的高维数据。看到这里各位不要过于兴奋，映射到高维空间中并非是有百利而无一害的。维数过高的害处就是会出现过度拟合。</span></li></ul><span style="background-color: white;">所以<b>选择合适的核函数以及软边缘参数C就是训练SVM的重要因素</b>。一般来讲，核函数越复杂，模型越偏向于拟合过度。在参数C方面，它可以看作是<a href="http://www.blogger.com/goog_1534229079">LASS</a></span><span style="background-color: white;"><a href="http://www.blogger.com/goog_1534229079">O</a></span><span style="background-color: white;"><a href="http://xccds1977.blogspot.com/2012/05/glmnetlasso.html">算法</a>中的lambda的倒数，C越大模型越偏向于拟合过度，反之则拟合不足。实际问题中怎么选呢？用人类最古老的办法，试错。</span><br /><br /><br /><a name='more'></a>常用的核函数有如下种类：<br /><ul><li><span style="background-color: white;">Linear：使用它的话就成为线性向量机，效果基本等价于Logistic回归。但它可以处理变量极多的情况，例如文本挖掘。</span></li><li><span style="background-color: white;">polynomial：多项式核函数，适用于图像处理问题。</span></li><li><span style="background-color: white;">Radial basis，高斯核函数，最流行易用的选择。参数包括了sigma，其值若设置过小，会有过度拟合出现。</span></li><li><span style="background-color: white;">sigmoid：反曲核函数，多用于神经网络的激活函数。</span></li></ul><span style="background-color: white;">好吧，理论说了一大堆，关键得在R里面出手。R语言中可以用<b>e1071包</b>中的<b>svm函数</b>建模，而另一个<b>kernlab包</b>中则包括了更多的核方法函数，本例用其中的<b>ksvm函数</b>，来说明参数C的作用和核函数的选择。我们先人为构造一个线性不可分的数据，先用线性核函数来建模，其参数C取值为1。然后我们用图形来观察建模结果，下图是根据线性SVM得到各样本的判别值等高线图（判别值decision value相当于Logistic回归中的X，X取0时为决策边界）。可以清楚的看到决策边界为线性，中间的决策边缘显示为白色区域，有相当多的样本落入此区域。</span><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-ezfwUOQy0vo/T_Zt5oxpVZI/AAAAAAAABBQ/TqnfyGDPcb4/s1600/Rplot01.jpeg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-ezfwUOQy0vo/T_Zt5oxpVZI/AAAAAAAABBQ/TqnfyGDPcb4/s1600/Rplot01.jpeg" /></a></div><span style="background-color: white;">下面为了更好的拟合，我们加大了C的取值，这样如下图所示。可以预料到，当加大惩罚参数后决策边缘缩窄，也使训练误差减少，但仍有个别样本未被正确的分类。</span><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-Vv3FUT5q1u0/T_ZuBjwkS_I/AAAAAAAABBY/vQzgbbz1w2Q/s1600/Rplot02.jpeg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://2.bp.blogspot.com/-Vv3FUT5q1u0/T_ZuBjwkS_I/AAAAAAAABBY/vQzgbbz1w2Q/s1600/Rplot02.jpeg" /></a></div><span style="background-color: white;">最后我们换用高斯核函数，这样得到的非线性决策边界。所有的样本都得到了正确的分类。</span><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-JKQDYjWoyZQ/T_ZuSbZ33aI/AAAAAAAABBg/qd4mi8JPpbA/s1600/Rplot03.jpeg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-JKQDYjWoyZQ/T_ZuSbZ33aI/AAAAAAAABBg/qd4mi8JPpbA/s1600/Rplot03.jpeg" /></a></div><span style="background-color: white;">在实际运用中，为了寻找最优参数我们还可以用caret包来配合建模，并且如同<a href="http://xccds1977.blogspot.com/2012/07/blog-post.html">前文</a>那样使用多重交叉检验来评价模型。还需要注意一点SVM建模最好先标准化处理。最后来总结一下SVM的优势：</span><br /><ul><li><span style="background-color: white;">可用于分类、回归和异常检验</span></li><li><span style="background-color: white;">可以发现全局最优解</span></li><li><span style="background-color: white;">可以用参数来控制过度拟合问题</span></li></ul><br /><span style="background-color: white;"><b>代码如下：</b></span><br /><div style="overflow: auto;"><div class="geshifilter"><pre class="r geshifilter-R"><span style="font-family: 'Courier New', Courier, monospace;"><span style="color: #666666; font-style: italic;"># 构造数据</span><br />x1 &lt;- <a href="http://inside-r.org/r-doc/base/seq"><span style="color: #003399;">seq</span></a><span style="color: #009900;">(</span><span style="color: #cc66cc;">0</span><span style="color: #339933;">,</span><span style="color: black;">pi</span><span style="color: #339933;">,</span>length.out=<span style="color: #cc66cc;">100</span><span style="color: #009900;">)</span><br />y1 &lt;- <a href="http://inside-r.org/r-doc/base/sin"><span style="color: #003399;">sin</span></a><span style="color: #009900;">(</span>x1<span style="color: #009900;">)</span> + <span style="color: #cc66cc;">0.1</span>*<a href="http://inside-r.org/r-doc/stats/rnorm"><span style="color: #003399;">rnorm</span></a><span style="color: #009900;">(</span><span style="color: #cc66cc;">100</span><span style="color: #009900;">)</span><br />x2 &lt;- <span style="color: #cc66cc;">1.5</span>+ <a href="http://inside-r.org/r-doc/base/seq"><span style="color: #003399;">seq</span></a><span style="color: #009900;">(</span><span style="color: #cc66cc;">0</span><span style="color: #339933;">,</span><span style="color: black;">pi</span><span style="color: #339933;">,</span>length.out=<span style="color: #cc66cc;">100</span><span style="color: #009900;">)</span><br />y2 &lt;- <a href="http://inside-r.org/r-doc/base/cos"><span style="color: #003399;">cos</span></a><span style="color: #009900;">(</span>x2<span style="color: #009900;">)</span> + <span style="color: #cc66cc;">0.1</span>*<a href="http://inside-r.org/r-doc/stats/rnorm"><span style="color: #003399;">rnorm</span></a><span style="color: #009900;">(</span><span style="color: #cc66cc;">100</span><span style="color: #009900;">)</span><br /><a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a> &lt;- <a href="http://inside-r.org/r-doc/base/data.frame"><span style="color: #003399;">data.frame</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/base/c"><span style="color: #003399;">c</span></a><span style="color: #009900;">(</span>x1<span style="color: #339933;">,</span>x2<span style="color: #009900;">)</span><span style="color: #339933;">,</span><a href="http://inside-r.org/r-doc/base/c"><span style="color: #003399;">c</span></a><span style="color: #009900;">(</span>y1<span style="color: #339933;">,</span>y2<span style="color: #009900;">)</span><span style="color: #339933;">,</span><a href="http://inside-r.org/r-doc/base/c"><span style="color: #003399;">c</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/base/rep"><span style="color: #003399;">rep</span></a><span style="color: #009900;">(</span><span style="color: #cc66cc;">1</span><span style="color: #339933;">,</span> <span style="color: #cc66cc;">100</span><span style="color: #009900;">)</span><span style="color: #339933;">,</span> <a href="http://inside-r.org/r-doc/base/rep"><span style="color: #003399;">rep</span></a><span style="color: #009900;">(</span>-<span style="color: #cc66cc;">1</span><span style="color: #339933;">,</span> <span style="color: #cc66cc;">100</span><span style="color: #009900;">)</span><span style="color: #009900;">)</span><span style="color: #009900;">)</span><br /><a href="http://inside-r.org/r-doc/base/names"><span style="color: #003399;">names</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a><span style="color: #009900;">)</span> &lt;- <a href="http://inside-r.org/r-doc/base/c"><span style="color: #003399;">c</span></a><span style="color: #009900;">(</span><span style="color: blue;">'x1'</span><span style="color: #339933;">,</span><span style="color: blue;">'x2'</span><span style="color: #339933;">,</span><span style="color: blue;">'y'</span><span style="color: #009900;">)</span><br /><a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a>$y &lt;- <a href="http://inside-r.org/r-doc/base/factor"><span style="color: #003399;">factor</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a>$y<span style="color: #009900;">)</span><br />&nbsp;<br /><span style="color: #666666; font-style: italic;"># 使用线性核函数，不能很好的划分数据</span><br />model1 &lt;- ksvm<span style="color: #009900;">(</span>y~.<span style="color: #339933;">,</span><a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a>=<a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a><span style="color: #339933;">,</span><a href="http://inside-r.org/r-doc/stats/kernel"><span style="color: #003399;">kernel</span></a>=<span style="color: blue;">'vanilladot'</span><span style="color: #339933;">,</span><a href="http://inside-r.org/r-doc/stats/C"><span style="color: #003399;">C</span></a>=<span style="color: #cc66cc;">0.1</span><span style="color: #009900;">)</span><br /><a href="http://inside-r.org/r-doc/graphics/plot"><span style="color: #003399;">plot</span></a><span style="color: #009900;">(</span>model1<span style="color: #339933;">,</span><a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a>=<a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a><span style="color: #009900;">)</span><br /><span style="color: #666666; font-style: italic;"># 加大惩罚参数，决策边缘缩窄，使训练误差减小</span><br />model2 &lt;- ksvm<span style="color: #009900;">(</span>y~.<span style="color: #339933;">,</span><a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a>=<a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a><span style="color: #339933;">,</span><a href="http://inside-r.org/r-doc/stats/kernel"><span style="color: #003399;">kernel</span></a>=<span style="color: blue;">'vanilladot'</span><span style="color: #339933;">,</span><a href="http://inside-r.org/r-doc/stats/C"><span style="color: #003399;">C</span></a>=<span style="color: #cc66cc;">100</span><span style="color: #009900;">)</span><br /><a href="http://inside-r.org/r-doc/graphics/plot"><span style="color: #003399;">plot</span></a><span style="color: #009900;">(</span>model2<span style="color: #339933;">,</span><a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a>=<a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a><span style="color: #009900;">)</span><br /><span style="color: #666666; font-style: italic;"># 使用高斯核函数，正确的分类</span><br />model3 &lt;- ksvm<span style="color: #009900;">(</span>y~.<span style="color: #339933;">,</span><a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a>=<a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a><span style="color: #339933;">,</span><a href="http://inside-r.org/r-doc/stats/kernel"><span style="color: #003399;">kernel</span></a>=<span style="color: blue;">'rbfdot'</span><span style="color: #009900;">)</span><br /><a href="http://inside-r.org/r-doc/graphics/plot"><span style="color: #003399;">plot</span></a><span style="color: #009900;">(</span>model3<span style="color: #339933;">,</span><a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a>=<a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a><span style="color: #009900;">)</span><br />&nbsp;<br /><span style="color: #666666; font-style: italic;"># 10折交叉检验训练iris数据，选择最优参数C为0.5</span><br />fitControl &lt;- trainControl<span style="color: #009900;">(</span>method = <span style="color: blue;">"repeatedcv"</span><span style="color: #339933;">,</span> number = <span style="color: #cc66cc;">10</span><span style="color: #339933;">,</span> repeats = <span style="color: #cc66cc;">3</span><span style="color: #339933;">,</span>returnResamp = <span style="color: blue;">"all"</span><span style="color: #009900;">)</span><br />model &lt;- train<span style="color: #009900;">(</span>Species~.<span style="color: #339933;">,</span> <a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a>=<a href="http://inside-r.org/r-doc/datasets/iris"><span style="color: #003399;">iris</span></a><span style="color: #339933;">,</span>method=<span style="color: blue;">'svmRadialCost'</span><span style="color: #339933;">,</span>trControl = fitControl<span style="color: #009900;">)</span></span></pre></div></div><br /><b>参考资料：</b><br /><span style="background-color: white;"><a href="http://www.autonlab.org/tutorials/svm15.pdf">http://www.autonlab.org/tutorials/svm15.pdf</a></span><br /><a href="http://www.jstatsoft.org/v15/i09/paper">http://www.jstatsoft.org/v15/i09/paper</a><br /><a href="http://www.broadinstitute.org/annotation/winter_course_2006/index_files/Noble%202006%20SVM%20tutorial%20Nat%20Biotech.pdf">http://www.broadinstitute.org/annotation/winter_course_2006/index_files/Noble%202006%20SVM%20tutorial%20Nat%20Biotech.pdf</a><br /><a href="http://cran.r-project.org/web/packages/kernlab/vignettes/kernlab.pdf">http://cran.r-project.org/web/packages/kernlab/vignettes/kernlab.pdf</a>
