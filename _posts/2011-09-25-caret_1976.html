--- 
layout: post
name: caret_1976
title: "caret\xE5\x8C\x85\xE5\xBA\x94\xE7\x94\xA8\xE4\xB9\x8B\xE4\xB8\x89\xEF\xBC\x9A\xE5\xBB\xBA\xE6\xA8\xA1\xE4\xB8\x8E\xE5\x8F\x82\xE6\x95\xB0\xE4\xBC\x98\xE5\x8C\x96"
date: 2011-09-25 11:28:00 +08:00
categories: 
- "\xE6\x8F\x90\xE5\x8D\x87\xE7\xAE\x97\xE6\xB3\x95"
- "\xE6\x95\xB0\xE6\x8D\xAE\xE6\x8C\x96\xE6\x8E\x98"
- "\xE5\x8F\x82\xE6\x95\xB0\xE4\xBC\x98\xE5\x8C\x96"
permalink: /2011/09/caret_1976.html
---
在进行建模时，需对模型的参数进行优化，在caret包中其主要函数命令是train。<br /><br />首先得到经过特征选择后的样本数据，并划分为训练样本和检验样本<br /><blockquote>newdata4=newdata3[,Profile$optVariables]<br />inTrain = createDataPartition(mdrrClass, p = 3/4, list = FALSE)<br />trainx = newdata4[inTrain,]<br />testx = newdata4[-inTrain,]<br />trainy = mdrrClass[inTrain]<br />testy = mdrrClass[-inTrain]</blockquote>然后定义模型训练参数，method确定多次交叉检验的抽样方法，number确定了划分的重数， repeats确定了反复次数。<br /><a name='more'></a><br /><blockquote>fitControl = trainControl(method = "repeatedcv", number = 10, repeats = 3,returnResamp = "all")</blockquote>确定参数选择范围，本例建模准备使用gbm算法，相应的参数有如下三项<br /><blockquote>gbmGrid = expand.grid(.interaction.depth = c(1, 3),.n.trees = c(50, 100, 150, 200, 250, 300),.shrinkage = 0.1)</blockquote>利用train函数进行训练，使用的建模方法为提升决策树方法，<br /><blockquote>gbmFit1 = train(trainx,trainy,method = "gbm",trControl = fitControl,tuneGrid = gbmGrid,verbose = FALSE)</blockquote>从结果可以观察到interaction.depth取1，n.trees取150时精度最高<br /><span class="Apple-style-span" style="-webkit-border-horizontal-spacing: 0px; -webkit-border-vertical-spacing: 0px; border-collapse: separate; font-family: Arial;"><span class="Apple-style-span" style="font-family: 'Lucida Console'; font-size: 13px; line-height: 17px; text-align: -webkit-left; white-space: pre-wrap;"></span></span><br /><pre class="GD40030CKR" style="border-bottom-style: none; border-color: initial; border-left-style: none; border-right-style: none; border-top-style: none; border-width: initial; font-family: 'Lucida Console'; font-size: 10pt !important; line-height: 1.3; outline-color: initial; outline-style: none; outline-width: initial; white-space: pre-wrap !important;" tabindex="0">interaction.depth  n.trees  Accuracy  Kappa  Accuracy SD  Kappa SD<br />  1                  50       0.822     0.635  0.0577       0.118   <br />  1                  100      0.824     0.639  0.0574       0.118   <br />  1                  150      0.826     0.643  0.0635       0.131   <br />  1                  200      0.824     0.64   0.0605       0.123   <br />  1                  250      0.816     0.623  0.0608       0.124   <br />  1                  300      0.824     0.64   0.0584       0.119   <br />  3                  50       0.816     0.621  0.0569       0.117   <br />  3                  100      0.82      0.631  0.0578       0.117   <br />  3                  150      0.815     0.621  0.0582       0.117   <br />  3                  200      0.82      0.63   0.0618       0.125   <br />  3                  250      0.813     0.617  0.0632       0.127   <br />  3                  300      0.812     0.615  0.0622       0.126   </pre><br />同样的图形观察<br /><blockquote>plot(gbmFit1)</blockquote><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-rT_H3OzF58M/Tn6f1s8FnAI/AAAAAAAAAb8/djdlaQnFGlg/s1600/Rplot02.jpeg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="267" src="http://2.bp.blogspot.com/-rT_H3OzF58M/Tn6f1s8FnAI/AAAAAAAAAb8/djdlaQnFGlg/s400/Rplot02.jpeg" width="400" /></a></div><br />
