--- 
layout: post
name: r
title: "R\xE8\xAF\xAD\xE8\xA8\x80\xE5\xA4\x9A\xE5\x85\x83\xE5\x88\x86\xE6\x9E\x90\xE7\xB3\xBB\xE5\x88\x97\xE4\xB9\x8B\xE4\xBA\x94\xEF\xBC\x9A\xE8\x81\x9A\xE7\xB1\xBB\xE5\x88\x86\xE6\x9E\x90\xEF\xBC\x88\xE5\xAE\x8C\xEF\xBC\x89"
date: 2012-01-02 12:26:00 +08:00
categories: 
- "\xE8\x81\x9A\xE7\xB1\xBB\xE5\x88\x86\xE6\x9E\x90"
- "\xE5\xA4\x9A\xE5\x85\x83\xE5\x88\x86\xE6\x9E\x90"
permalink: /2012/01/r.html
---
<b>聚类分析（Cluster Analysis）</b>是根据“物以类聚”的道理，对样品或指标进行分类的一种多元统计分析方法，它是在没有先验知识的情况下，对样本按各自的特性来进行合理的分类。<br /><br />聚类分析被应用于很多方面，在商业上，聚类分析被用来发现不同的客户群，并且通过购买模式刻画不同的客户群的特征；在生物上，聚类分析被用来动植物分类和对基因进行分类，获取对种群固有结构的认识；在因特网应用上，聚类分析被用来在网上进行文档归类来修复信息。<br /><a name='more'></a><br /><br />聚类分析有两种主要计算方法，分别是凝聚层次聚类（Agglomerative hierarchical method）和K均值聚类（K-Means）。<br /><br /><b><span style="font-size: large;">一、层次聚类</span></b><br />层次聚类又称为系统聚类，首先要定义样本之间的距离关系，距离较近的归为一类，较远的则属于不同的类。可用于定义“距离”的统计量包括了欧氏距离(euclidean)、马氏距离(manhattan)、 两项距离(binary)、明氏距离(minkowski)。还包括相关系数和夹角余弦。<br /><br />层次聚类首先将每个样本单独作为一类，然后将不同类之间距离最近的进行合并，合并后重新计算类间距离。这个过程一直持续到将所有样本归为一类为止。在计算类间距离时则有六种不同的方法，分别是最短距离法、最长距离法、类平均法、重心法、中间距离法、离差平方和法。<br /><br />下面我们用<b>iris</b>数据集来进行聚类分析，在R语言中所用到的函数为<b>hclust</b>。首先提取iris数据中的4个数值变量，然后计算其欧氏距离矩阵。然后将矩阵绘制热图，从图中可以看到颜色越深表示样本间距离越近，大致上可以区分出三到四个区块，其样本之间比较接近。<br /><div style="overflow: auto;"><div class="geshifilter"><pre class="r geshifilter-R"><span style="font-family: 'Courier New', Courier, monospace;"><a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a>=<a href="http://inside-r.org/r-doc/datasets/iris"><span style="color: #003399;">iris</span></a><span style="color: #009900;">[</span><span style="color: #339933;">,</span>-<span style="color: #cc66cc;">5</span><span style="color: #009900;">]</span><br />dist.e=<a href="http://inside-r.org/r-doc/stats/dist"><span style="color: #003399;">dist</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a><span style="color: #339933;">,</span>method=<span style="color: blue;">'euclidean'</span><span style="color: #009900;">)</span><br /><a href="http://inside-r.org/r-doc/stats/heatmap"><span style="color: #003399;">heatmap</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/base/as.matrix"><span style="color: #003399;">as.matrix</span></a><span style="color: #009900;">(</span>dist.e<span style="color: #009900;">)</span><span style="color: #339933;">,</span>labRow = F<span style="color: #339933;">,</span> labCol = F<span style="color: #009900;">)</span></span></pre></div></div><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-v7w5MRPW5oM/TwExV2TUyNI/AAAAAAAAAoo/y7e8TElNh-Q/s1600/Rplot01.jpeg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://2.bp.blogspot.com/-v7w5MRPW5oM/TwExV2TUyNI/AAAAAAAAAoo/y7e8TElNh-Q/s1600/Rplot01.jpeg" /></a></div>然后使用hclust函数建立聚类模型，结果存在model1变量中，其中ward参数是将类间距离计算方法设置为离差平方和法。使用plot(model1)可以绘制出聚类树图。如果我们希望将类别设为3类，可以使用cutree函数提取每个样本所属的类别。  <br /><pre class="r geshifilter-R"><span style="font-family: 'Courier New', Courier, monospace;">model1=<a href="http://inside-r.org/r-doc/stats/hclust"><span style="color: #003399;">hclust</span></a><span style="color: #009900;">(</span>dist.e<span style="color: #339933;">,</span>method=<span style="color: blue;">'ward'</span><span style="color: #009900;">)</span><br />result=<a href="http://inside-r.org/r-doc/stats/cutree"><span style="color: #003399;">cutree</span></a><span style="color: #009900;">(</span>model1<span style="color: #339933;">,</span>k=<span style="color: #cc66cc;">3</span><span style="color: #009900;">)</span></span></pre>为了显示聚类的效果，我们可以结合多维标度和聚类的结果。先将数据用MDS进行降维，然后以不同的的形状表示原本的分类，用不同的颜色来表示聚类的结果。可以看到setose品种聚类很成功，但有一些virginica品种的花被错误和virginica品种聚类到一起。 <br /><pre class="r geshifilter-R"><span style="font-family: 'Courier New', Courier, monospace;">mds=<a href="http://inside-r.org/r-doc/stats/cmdscale"><span style="color: #003399;">cmdscale</span></a><span style="color: #009900;">(</span>dist.e<span style="color: #339933;">,</span>k=<span style="color: #cc66cc;">2</span><span style="color: #339933;">,</span>eig=T<span style="color: #009900;">)</span><br />x = mds$points<span style="color: #009900;">[</span><span style="color: #339933;">,</span><span style="color: #cc66cc;">1</span><span style="color: #009900;">]</span><br />y = mds$points<span style="color: #009900;">[</span><span style="color: #339933;">,</span><span style="color: #cc66cc;">2</span><span style="color: #009900;">]</span><br /><a href="http://inside-r.org/r-doc/base/library"><span style="color: #003399;">library</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/packages/cran/ggplot2">ggplot2</a><span style="color: #009900;">)</span><br />p=<a href="http://inside-r.org/packages/cran/ggplot">ggplot</a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/base/data.frame"><span style="color: #003399;">data.frame</span></a><span style="color: #009900;">(</span>x<span style="color: #339933;">,</span>y<span style="color: #009900;">)</span><span style="color: #339933;">,</span>aes<span style="color: #009900;">(</span>x<span style="color: #339933;">,</span>y<span style="color: #009900;">)</span><span style="color: #009900;">)</span><br />p+geom_point<span style="color: #009900;">(</span>size=<span style="color: #cc66cc;">3</span><span style="color: #339933;">,</span>alpha=<span style="color: #cc66cc;">0.8</span><span style="color: #339933;">,</span><br />             aes<span style="color: #009900;">(</span>colour=<a href="http://inside-r.org/r-doc/base/factor"><span style="color: #003399;">factor</span></a><span style="color: #009900;">(</span>result<span style="color: #009900;">)</span><span style="color: #339933;">,</span><br />               <a href="http://inside-r.org/packages/cran/shape">shape</a>=<a href="http://inside-r.org/r-doc/datasets/iris"><span style="color: #003399;">iris</span></a>$Species<span style="color: #009900;">)</span><span style="color: #009900;">)</span></span></pre><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-SfKrATm2UYQ/TwExzEg6S0I/AAAAAAAAAo0/oAjt5ljWVyo/s1600/Rplot.jpeg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-SfKrATm2UYQ/TwExzEg6S0I/AAAAAAAAAo0/oAjt5ljWVyo/s1600/Rplot.jpeg" /></a></div><pre class="r geshifilter-R"><span style="font-family: 'Courier New', Courier, monospace;"><span style="color: #009900;"><br /></span></span></pre><b><span style="font-size: large;">二、K均值聚类</span></b><br />K均值聚类又称为动态聚类，它的计算方法较为简单，也不需要输入距离矩阵。首先要指定聚类的分类个数N，随机取N个样本作为初始类的中心，计算各样本与类中心的距离并进行归类，所有样本划分完成后重新计算类中心，重复这个过程直到类中心不再变化。<br /><br />在R中使用<b>kmeans</b>函数进行K均值聚类，centers参数用来设置分类个数，nstart参数用来设置取随机初始中心的次数，其默认值为1，但取较多的次数可以改善聚类效果。model2$cluster可以用来提取每个样本所属的类别。 <br /><pre class="r geshifilter-R"><span style="font-family: 'Courier New', Courier, monospace;">model2=<a href="http://inside-r.org/r-doc/stats/kmeans"><span style="color: #003399;">kmeans</span></a><span style="color: #009900;">(</span><a href="http://inside-r.org/r-doc/utils/data"><span style="color: #003399;">data</span></a><span style="color: #339933;">,</span>centers=<span style="color: #cc66cc;">3</span><span style="color: #339933;">,</span>nstart=<span style="color: #cc66cc;">10</span><span style="color: #009900;">)</span></span></pre>使用K均值聚类时需要注意，只有在类的平均值被定义的情况下才能使用，还要求事先给出分类个数。一种方法是先用层次聚类以决定个数，再用K均值聚类加以改进。或者以<a href="http://xccds1977.blogspot.com/2011/08/k.html" target="_blank">轮廓系数</a>来判断分类个数。改善聚类的方法还包括对原始数据进行变换，如对数据进行降维后再实施聚类。<br /><br />cluster扩展包中也有许多函数可用于聚类分析，如agnes函数可用于凝聚层次聚类，diana可用于划分层次聚类，pam可用于K均值聚类，fanny用于模糊聚类。
